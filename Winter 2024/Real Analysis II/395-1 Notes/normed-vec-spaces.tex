\chapter{Normed Vector Spaces}
\pagenumbering{arabic}

\section{Vector Spaces}
    \begin{definition}
        A \textit{vector space} over a field $F$ is a nonempty set $V$ equipped with two operations:
            \begin{equation*}
            \begin{split}
                V \times V \xrightarrow{+}V &\mtext{defined by} (v,w)\mapsto v+w \\
                F \times V \rightarrow V &\mtext{defined by} (\alpha,v)\mapsto \alpha v
            \end{split}
            \end{equation*}
        satisfying:
            \begin{enumerate}[label = (\arabic*)]
                \item $(V,+)$ is an abelian group;
                \item $\alpha(v+w) = \alpha v + \alpha w$ for all $\alpha \in F$, $v,w \in V$;
                \item $\alpha(\beta v) = (\alpha \beta)v$ for all $\alpha,\beta \in F$, $v \in V$;
                \item $1_F v = v$ for all $v \in V$.
            \end{enumerate}
    \end{definition}

    \begin{definition}
        Let $V$ be a vector spaces over $F$. A \textit{subspace} is a nonempty set $W \subseteq V$ satisfying $w_1 + \alpha w_2 \in W$ for all $w_1,w_2 \in W$ and $\alpha \in F$.
    \end{definition}

    \begin{exercise}\label{ex:intersection}
        If $\{W_i\}_{i \in I}$ is a family of subspaces of $V$, then $\bigcap_{i \in I}W_i$ is a subspace of $V$.
    \end{exercise}

    \begin{exercise}\label{ex:union}
        If $W_1,W_2 \subseteq V$ are subspaces such that $W_1 \cup W_2$ is a subspace, then $W_1 \subseteq W_2$ or $W_2 \subseteq W_1$.
    \end{exercise}

    \begin{definition}
        Let $S \subseteq V$ be any subset of a vector space $V$. Then:
            \begin{equation*}
            \begin{split}
                \Span(S) = \left\{\sum_{j = 1}^n \alpha_j v_j \mid \alpha_j \in F, v_j \in S\right\}.
            \end{split}
            \end{equation*}
    \end{definition}

    \begin{note} \phantom{a}
        \begin{enumerate}[label = (\arabic*)]
            \item $\Span(S) \subseteq V$ is a subspace.
            \item $\Span(S) = \bigcap W$, where $S \subseteq W$ and $W \subseteq V$ is a subspace. So $\Span(S)$ is the "smallest" subspace containing $S$, or equivalently the subspace generated by $S$.
        \end{enumerate}
    \end{note}

    \begin{proposition}[Quotient Spaces]
        Let $V$ be a vector space and let $W \subseteq V$ be a subspace. Define $u \sim_W v$ if and only if $u - v \in W$.
            \begin{enumerate}[label = (\arabic*)]
                \item $\sim_W$ is an equivalent relation.
                \item If $[v]_W$ denotes the equivalence classes of $v$, then $[v]_W = v+W = \{v+w \mid w \in W\}$.
                \item $V/W := \{[v]_W \mid v \in V\}$ is a vector space with $[v_1]_W + [v_2]_W = [v_1 + v_2]_W$ and  $\alpha[v]_W = [\alpha v]_W$.
            \end{enumerate}
    \end{proposition}
        \begin{proof}
            Exercise.
        \end{proof}

    \begin{definition}
        Let $V$ be a vector space and $S \subseteq V$ be a subset.
            \begin{enumerate}[label = (\arabic*)]
                \item $S$ is said to \textit{span} $V$ if $\Span(S) = V$.
                \item $S$ is \textit{linearly independent} if, for all $\alpha_j \in F$ and $v_j \in V$, $\sum_{j = 1}^n \alpha_j v_j = 0_V$ implies $\alpha_j = 0_V$ for all $j$.
                \item $S$ is a \textit{basis} for $V$ if $S$ is linearly independent and spans $V$.
            \end{enumerate}
    \end{definition}

    \begin{proposition}
        Every vector space admits a basis. Moreover, if $B_0 \subseteq V$ is a linearly independent set, there exists $B \subseteq V$ such that $B$ is a basis and $B_0 \subseteq B$.
    \end{proposition}
        \begin{proof}
            Let $X = \{D \mid B_0 \subseteq D \subseteq V, \mtext{$D$ linearly independent}\hspace{-4pt}\}$. Define an ordering on $X$ as follows: given $D,E \in X$, we have $D \leq E$ if and only if $D \subseteq E$. We will show that $X$ admits a maximal element. \nl
            
            Note that $X$ is nonempty because $B_0 \in X$. Let $\{D_i\}_{i \in I}$ be a family of linearly indepedent sets satisfying $D_i \subseteq V$ for all $i$. Suppose $Y = (\{D_i\}_{i \in I}, \leq)$ is a totally ordered set. Consider $D = \bigcup_{i \in I}D_i$. Clearly $B_0 \subseteq D \subseteq V$. If $\sum_{j = 1}^n \alpha_j v_j = 0_V$ with $v_1,...,v_n \in D$, then since $Y$ is totally ordered, there exists $D_K$ with $v_1,...,v_n \in D_k$. Since $D_k$ is linearly independent, we have that $\alpha_1 = ... = \alpha_n = 0$. Thus $D$ is linearly independent, whence $D \in X$. Furthermore, $D$ is clearly an uppoerbound of $Y$. By Zorn's Lemma, $X$ has a maximal element $B$. \nl
            
            Claim: $B$ is a basis for $V$. Suppose towards contradiction its not, that is, there exists $v \in V$ with $v \not\in \Span(B)$. Consider $B' = B \cup \{v\}$. Let $\sum_{j = 1}^n \alpha_j v_j + \alpha v = 0_V$ with $v_1,...,v_n \in B$. We proceed by cases. \nl
            
            Case 1: $\alpha \neq 0$. Then $\sum_{j =1}^n \alpha_j v_j = -\alpha v$, meaning $v \in \Span(B)$. $\bot$ \nl
            
            Case 2: $\alpha = 0$. Then $\alpha_1 = ... = \alpha_n = 0$. This gives that $B'$ is a linearly independent set, with $B' \in X$ and $B \subseteq B'$. $\bot$ This contradicts the maximality of $B$. \nl
            
            Thus $\Span(B) = V$, giving $B$ as a basis for $V$.
        \end{proof}

    \newpage
    \begin{example}[Examples of Vector Spaces]
        \phantom{a}
        \begin{enumerate}[label = (\arabic*)]
            \item The set of $n$-dimensional vectors; $F^n = \{(x_1,...,x_n) \mid x_i \in F\}$ is a vector space by defining addition and scalar multiplication componentwise.
            
            \item The set of $m \times n$ matrices over a field; $M_{n,m}(F) = \{(a_{ij}) \mid a_{ij} \in F\}$ is a vector space by the usual matrix addition and scalar multiplication.
            
            \item The set of functions with domain $\Omega$;  $\cF(\Omega,F) = \{f \mid f:\Omega \rightarrow f\}$ is a vector space by defining addition and scalar multiplication pointwise.
            
            \item The set of bounded functions with domain $\Omega$; $\ell_\infty(\Omega,F) = \{f \in \cF(\Omega,F) \mid  \lVert f \rVert _u < \infty\}$ is a vector space by defining addition and scalar multiplication componentwise.
                \begin{exercise}\label{ex:bounded-met-space}
                    Show that $(\ell_\infty, \lVert \cdot \rVert _u)$ forms a metric space.
                \end{exercise}
            
            \item Continuous functions on a bounded domain: \newline$C([a,b], F) = \{f:[a,b] \rightarrow F \mid \hspace{-4pt}\mtext{$f$ continuous}\hspace{-4pt}\}$ by defining addition and scalar multiplication componentwise.
                \begin{exercise}\label{ex:cont-subspace}
                    Show that $C([a,b], F) \subseteq \ell_\infty([a,b],F)$ is a subspace.
                \end{exercise}

            \item Let $f:[a,b] \rightarrow \bfR$ be any function. Let $\cP = \{a = x_0 < x_1 < ... < x_{n-1} < x_n = b\}$ be a partition of $[a,b]$. The \textit{variation of $f$ on $\cP$} is defined as:
                \begin{equation*}
                \begin{split}
                    \text{Var}(f;\cP) = \sum_{k = 1}^n |f(x_k) - f(x_{k-1})|.
                \end{split}
                \end{equation*}
            We say $f$ is a \textit{bounded variation} if:
                \begin{equation*}
                \begin{split}
                    \text{Var}(f) := \sup_{\cP}\text{Var}(f;\cP) < \infty.
                \end{split}
                \end{equation*}
            The set of all functions of bounded variation is defined:
                \begin{equation*}
                \begin{split}
                    \text{BV}([a,b]) = \{f:[a,b] \rightarrow \bfR \mid \text{Var}(f) < \infty\}.
                \end{split}
                \end{equation*}
            This is a vector space by defining addition and scalar multiplication componentwise.
                \begin{exercise}\label{ex:bv-subspace}
                    Show that $\text{BV([a,b])} \subseteq \ell_\infty([a,b],\bfR)$ is a subspace.
                \end{exercise}
            
            \item A subset $K \subseteq V$ of a vector space is \textit{convex} if, for all $v,w \in K$ and $t \in [0,1]$, then $(1-t)v + tw \in K$. A function $f:K \rightarrow \bfR$ is \textit{affine} if, for all $v,w \in K$ and $t \in [0,1]$, then $f((1-t)v + tw) = (1-t)f(v) + tf(w)$. The set of all affine functions over a convex subset $\text{Aff}(K) = \{f:K \rightarrow \bfR \mid \hspace{-4pt}\mtext{$f$ affine}\hspace{-4pt}\}$ is a vector space by defining addition and scalar multiplication componentwise. 
                \begin{exercise}\label{ex:aff-subspace}
                    Show that $\text{Aff}(K) \subseteq \cF(K,\bfR)$ is a subspace.
                \end{exercise}

            \item By (3), the set of all sequences $\cF(\bfN, F) = \{(a_k)_k \mid a_k \in F\}$ is a vector space. Define:
                \begin{equation*}
                \begin{split}
                    c_{00} & = \{(a_k)_k \mid \supp((a_k)_k) < \infty\} \\
                    c_0 & = \{(a_k)_k \mid (a_k)_k \rightarrow 0\} \\
                    c &= \{(a_k)_k \mid (a_k)_k \mtext{converges}\hspace{-4pt}\} \\
                    \ell_\infty(\bfN,F) &= \{(a_k)_k \mid \lVert (a_k)_k \rVert _u < \infty\} \\
                    \ell_1(\bfN,F) & = \left\{(a_k)_k \hspace{4pt} \Bigg|\hspace{4pt} \sum_{k = 1}^\infty |a_k| < \infty \right\}.
                \end{split}
                \end{equation*}
            These are similarly vector spaces with addition and scalar mutliplcation defined componentwise.
                \begin{exercise}\label{ex:seq-subspace}
                    Show that the above vector spaces are subspaces of $\cF(\bfN,F)$.
                \end{exercise}

            \item Recall that a function $f:\bfR \rightarrow F$ is \textit{compactly supported} if there exists $[a,b]\subseteq \bfR$ such that $x \not\in [a,b]$ implies $f(x) = 0$. Then $C_c(\bfR) := \{f:\bfR \rightarrow F \mid f \mtext{compactly supported}\hspace{-4pt}\}$ is a vector space with addition and scalar multiplication defined pointwise.
            
            \item The set of functions which vanish at infinity; \newline $C_0(\bfR) = \{f:\bfR \rightarrow F \mid f \mtext{continuous,} \limit_{x\rightarrow \pm \infty}f = 0\}$ is a vector space with addition and scalar multiplication defined pointwise.
                \begin{exercise}\label{ex:funct-subspace}
                    Show that $C_c(\bfR) \subseteq C_0(\bfR) \subseteq \ell_\infty(\bfR)$ are subspaces.
                \end{exercise}

            \item Let $\Gamma$ be a nonempty set. The free vector space $\bfF(\Gamma) = \{f:\Gamma \rightarrow F \mid \supp(f) < \infty \}$ is a vector space with addition and scalar multiplication defined pointwise. \nl
            
            Fix $t \in \Gamma$. Recall that $\delta_t:\Gamma \rightarrow F$ is defined by:
                \begin{equation*}
                \begin{split}
                    \delta_t (s) = \begin{cases} 1, & s = t \\ 0, & s \neq t \end{cases}.
                \end{split}
                \end{equation*}
            We have that $\delta_t \in \cF(\Gamma,F)$, and furthermore $\supp(\delta_t) = \{t \}$. If $f \in \cF(\Gamma,F)$ has finite support, then $\supp(f) = \{t_1,...,t_n\}$ for some $t_i \in F$. If $f(t_i) \neq 0$ for all $1\leq i \leq n$, then we can write $f = \sum_{j = 1}^n f(t_j) \delta_{t_j}$. \nl
            
            Define $\iota:\Gamma \rightarrow \bfF(\Gamma)$ by $\iota(x) = \delta_x$. We have the following universal property: if $W$ is any vector space and $t:\Gamma \rightarrow W$ is a map of sets, there is a unique $T \in \Hom_F(\bfF(\Gamma),W)$ such that $T(x) = t(x)$ for every $x \in \Gamma$; i.e., the following diagram commutes:
            \begin{center}
            \begin{tikzcd}
                \Gamma \arrow[r, "\iota", hook] \arrow[rd, "t"'] & \bbF(\Gamma) \arrow[d, "T"] \\
                                                            & W                  
            \end{tikzcd}.
            \end{center}
                \begin{exercise}\label{ex:free-vec}
                    \phantom{a}
                    \begin{enumerate}[label = (\arabic*)]
                        \item Show that $\bfF(\Gamma) \subseteq \cF(\Gamma,F)$ is a subspace.
                        \item Show that $\{\delta_t\}_{t \in \Gamma}$ is a basis for $\bfF(\Gamma)$.
                        \item Prove the above universal property.
                        \item Suppose $V$ is a vector space over $F$ with basis $B$. Show that $\bfF(B) \cong V$.
                    \end{enumerate}
                \end{exercise}
        \end{enumerate}
    \end{example}

\section{Normed Spaces}
    \begin{definition}
        A \textit{norm} on a vector space $V$ is a map:
            \begin{equation*}
            \begin{split}
                \lVert \cdot \rVert : V \rightarrow \bfR^+ \mtext{defined by} v \mapsto \lVert v \rVert \geq 0.
            \end{split}
            \end{equation*}
        satisfying:
            \begin{enumerate}[label = (\arabic*)]
                \item $\lVert \alpha v \rVert = |\alpha| \lVert v\rVert$ for all $\alpha \in F$, $v \in V$ (homogeneity);
                \item $\lVert v + w \rVert \leq \lVert v \rVert + \lVert w \rVert$ for all $v,w \in V$ (triangle inequality);
                \item If $\lVert v \rVert = 0$, then $v = 0_V$ (positive definiteness).
            \end{enumerate}
        If $\lVert \cdot \rVert$ satisifes only (1) and (2), then we say it is a \textit{seminorm}. The pair $(V,\lVert \cdot \rVert)$ is called a \textit{normed space}.
    \end{definition}

    \begin{definition}
        Two norms $\lVert \cdot \rVert _1$ and $\lVert \cdot \rVert _2$ are called \textit{equivalent} if there exists $\alpha,\beta \geq 0$ satisfying:
            \begin{equation*}
            \begin{split}
                \lVert v \rVert _1 \leq \alpha \lVert v \rVert _2 \\
                \lVert v \rVert _2 \leq \beta \lVert v \rVert _1
            \end{split}
            \end{equation*}
        for all $v \in V$.
    \end{definition}

    \begin{note}
        On $\bfR^n$, all norms are equivalent.
    \end{note}

    \begin{exercise}\label{ex:seminorm}
        Let $v,w \in V$. If $p$ is any seminorm on $V$, then $|p(v) - p(w)| \leq p(v-w)$.
    \end{exercise}

    \begin{definition}
        Let $V$ be any normed space.
            \begin{enumerate}[label = (\arabic*)]
                \item The \textit{open ball of radius $r$} is denoted $U_V = \{v \in V \mid \lVert v \rVert < r\}$.
                \item The \textit{closed ball of radius $r$} is denoted $B_V = \{v \in V \mid \lVert v \rVert \leq r\}$.
            \end{enumerate}
    \end{definition}

    \begin{example}[Examples of Norms]
        Given $V = F^n$ and $x = (x_1,...,x_n)$, we have the following norms:
            \begin{enumerate}[label = (\arabic*)]
                \item $\ds \lVert x \rVert _1 = \sum_{j = 1}^n |x_j|$;
                \item $\ds \lVert x \rVert _\infty = \max_{1 \leq j \leq n}|x_j|$;
                \item $\ds \lVert x \rVert _2 = \left(\sum_{j = 1}^n |x_j|^2\right)^\frac{1}{2}$.
            \end{enumerate}
    \end{example}

    \begin{exercise}\label{ex:1-infty-norm}
        Show that $\lVert \cdot \rVert _1$ and $\lVert \cdot \rVert _\infty$ are norms.
    \end{exercise}

    \begin{lemma}\label{lemma:lemnorm1}
        Let $p,q \in [1,\infty]$ with $\frac{1}{p} + \frac{1}{q} = 1$. Let $f:[0,\infty) \rightarrow \bfR$ be defined by $f(t) = \frac{1}{p}t^p - t + \frac{1}{q}$. Then $f(t) \geq 0$ for $t \geq 0$.
    \end{lemma}
        \begin{proof}
            Note that $f'(t) = t^{p-1} - 1$. Since:
                \begin{equation*}
                \begin{split}
                    f'(1) &= 0 \\
                    f'(t) &> 0 \mtext{for} t>1 \\
                    f'(t) &<0 \mtext{for} 0\leq t < 1,
                \end{split}
                \end{equation*}
            we can see that $f(t) \geq 0$ for all $t \geq 0$.
        \end{proof}

    \begin{lemma}
        Let $p,q \in [0,\infty]$ with $\frac{1}{p} + \frac{1}{q} = 1$. If $x,y \geq 0$, then $xy \leq \frac{1}{p}x^p + \frac{1}{q}y^q$. 
    \end{lemma}
        \begin{proof}
            By Lemma~\ref{lemma:lemnorm1}, $t \leq \frac{1}{p}t^p + \frac{1}{q}$. Multiplying both sides by $y^q$ gives:
                \begin{equation*}
                \begin{split}
                    ty^q \leq \frac{1}{p}t^p y^q + \frac{1}{q}y^q.
                \end{split}
                \end{equation*}
            Let $t = xy^{1-q}$. Then:
                \begin{equation*}
                \begin{split}
                    xy^{1-q}y^q \leq \frac{1}{p}x^p y^{p-pq}y^q + \frac{1}{q}y^q.
                \end{split}
                \end{equation*}
            Since $\frac{1}{p} + \frac{1}{q} = 1$, we have that $p-pq = -q$. Whence:
                \begin{equation*}
                \begin{split}
                    xy \leq \frac{1}{p}x^p + \frac{1}{q}y^q.
                \end{split}
                \end{equation*}
        \end{proof}

    \begin{definition}
        Let $V = F^n$, $x = (x_1,...,x_n)$, and $p \geq 1$. We define:
            \begin{equation*}
            \begin{split}
                \lVert x \rVert _p := \left( \sum_{j = 1}^n |x_j|^p \right)^\frac{1}{p}.
            \end{split}
            \end{equation*}
    \end{definition}

    \begin{lemma}[H\"olders Inequality]\label{lemma:holders}
        Let $p,q \in [0,\infty]$ with $\frac{1}{p} + \frac{1}{q} = 1$. Then for $x,y \in F^n$:
            \begin{equation*}
            \begin{split}
                \left|\sum_{j = 1}^n x_j y_j\right| \leq \lVert x \rVert _p \lVert y \rVert _q.
            \end{split}
            \end{equation*}
    \end{lemma}
        \begin{proof}
            We proceed by cases. \nl
            
            Case 1: $p=1$. Then:
                \begin{equation*}
                \begin{split}
                    \left|\sum_{j = 1}^n x_j y_j\right|
                    & \leq \sum_{j = 1}^n |x_j||y_j| \\
                    & \leq \sum_{j = 1}^n |x_j| \lVert y \rVert _\infty \\
                    & = \lVert x \rVert _1 \lVert y \rVert _\infty.
                \end{split}
                \end{equation*}

            Case 2: $p = \infty$. This follows similarly to Case 1. \nl
            
            Case 3: $1 < p < \infty$. Suppose $\lVert x \rVert _p = \lVert y \rVert _q =1 $. Then:
                \begin{equation*}
                \begin{split}
                    \left|\sum_{j = 1}^n x_j y_j\right|
                    & \leq \sum_{j = 1}^n |x_j||y_j| \\
                    & \leq \sum_{j =1}^n \left(\frac{1}{p}|x_j|^p + \frac{1}{q}|y_j|^q\right) \\
                    & = \frac{1}{p} \left(\sum_{j = 1}^n |x_j|^p\right) + \frac{1}{q} \left(\sum_{j = 1}^n|y_j|^q\right) \\
                    & = \frac{1}{p} + \frac{1}{q} \\
                    & = 1.
                \end{split}
                \end{equation*}
            Whence the inequality holds. Now suppose $\lVert v \rVert _p = 0$ or $\lVert y \rVert _q = 0$. Then $x = 0_{F^n}$ or $y = 0_{F^n}$, whence the inequality holds. Suppose $\lVert x \rVert _p \neq 0$ and $\lVert y \rVert _p \neq 0$. Set:
                \begin{equation*}
                \begin{split}
                    x' = \frac{x}{\lVert x \rVert _p} \\
                    y' = \frac{y}{ \lVert y \rVert _p}.
                \end{split}
                \end{equation*}
            Then $\lVert x' \rVert _p = 1 = \lVert y' \rVert _p$. Observe that:
                \begin{equation*}
                \begin{split}
                    1 &\geq \left|\sum_{j = 1}^n x_j' y_j'\right| \\
                    & = \left|\sum_{j = 1}^n \frac{x}{\lVert x \rVert _p}\frac{y}{ \lVert y \rVert _p}\right|.
                \end{split}
                \end{equation*}
            Multiplying both sides by $\lVert x \rVert _p \lVert y \rVert _q$ gives the desired result.
        \end{proof}

    \begin{lemma}[Minkowski's Inequality]\label{lemma:minkowski}
        Let $p,q \in [1,\infty]$ with $\frac{1}{p} + \frac{1}{q} = 1$. For $x,y \in F^n$:
            \begin{equation*}
            \begin{split}
                \lVert x + y \rVert _p \leq \lVert x \rVert _p + \lVert y \rVert _p.
            \end{split}
            \end{equation*}
    \end{lemma}
        \begin{proof}
            The only nontrivial case is for $1 < p < \infty$. Observe that:
                \begin{equation*}
                \begin{split}
                    \left(\lVert x + y \rVert _p\right)^p 
                    & = \sum_{j = 1}^n |x_j + y_j|^p \\
                    & = \sum_{j = 1}^n |x_j + y_j| |x_j + y_j|^{p-1} \\
                    & \leq \sum_{j = 1}^n |x_j||x_j + y_j|^{p-1} + 
                    |y_j||x_j + y_j|^{p-1} \\
                    & \leq \left(\sum_{j=1}^n |x_j|^p\right)^\frac{1}{p} \left(\sum_{j = 1}^n|x_j + y_j|^{(p-1)q}\right)^\frac{1}{q} + \left(\sum_{j = 1}^n |y_j|^p\right)^\frac{1}{p} \left(\sum_{j = 1}^n|x_j + y_j|^{(p-1)q}\right)^\frac{1}{q} \\
                    & = \left(\sum_{j=1}^n |x_j|^p\right)^\frac{1}{p} \left(\sum_{j = 1}^n|x_j + y_j|^{p-1 \left(\frac{p}{p-1}\right)}\right)^{1-\frac{1}{p}} + \left(\sum_{j = 1}^n |y_j|^p\right)^\frac{1}{p} \left(\sum_{j = 1}^n|x_j + y_j|^{p-1 \left(\frac{p}{p-1}\right)}\right)^{1-\frac{1}{p}} \\
                    & = \left(\sum_{j=1}^n |x_j|^p\right)^\frac{1}{p} \left(\sum_{j = 1}^n|x_j + y_j|^{p}\right)^{1-\frac{1}{p}} + \left(\sum_{j = 1}^n |y_j|^p\right)^\frac{1}{p} \left(\sum_{j = 1}^n|x_j + y_j|^{p}\right)^{1-\frac{1}{p}} \\
                    & = (\lVert x \rVert _p + \lVert y \rVert _p) \frac{\lVert x+y \rVert _p ^p}{\lVert x+y \rVert _p}.
                \end{split}
                \end{equation*}
            Multiplying boths sides by $\frac{\lVert x+y \rVert _p }{\lVert x+y \rVert _p ^p}$ gives the desired inequality.
        \end{proof}

    \begin{theorem}
        Let $V = F^n$. Then $(F^n, \lVert \cdot \rVert _p)$ is a normed space. In particular, $\lVert \cdot \rVert _p$ is a norm.
    \end{theorem}
        \begin{proof}
            Let $x = (x_1,...,x_n) \in F^n$ and $\alpha \in F$. Observe that:
                \begin{equation*}
                \begin{split}
                    \lVert  \alpha x \rVert _p
                    & = \left(\sum_{j = 1}^n |\alpha x_j|^p\right)^\frac{1}{p} \\
                    & = \left(\sum_{j = 1}^n |\alpha|^p |x_j|^p\right)^\frac{1}{p} \\
                    & = |\alpha| \lVert x \rVert _p.
                \end{split}
                \end{equation*}
            This satisfies homogeneity. Moreover, \nameref{lemma:minkowski} satisifes the triangle inequality. It remains to show that $\lVert \cdot \rVert _p$ is positive-definite. If $\lVert x \rVert _p = 0$, then $x_j = 0$ for all $1 \leq j \leq n$. Thus $x = 0_{F^n}$.
        \end{proof}

    \begin{example}[Examples of Normed Spaces]
        \phantom{a}
        \begin{enumerate}[label = (\arabic*)]
            \item $\left(\ell_\infty(\Omega,F),\lVert \cdot \rVert _u\right)$ is a normed space. Moreover, subspaces of $\ell_\infty(\Omega,F)$ inherit the norm, such as $C([a,b],F)$.
            \item Let $f \in C([a,b])$. Define:
                \begin{equation*}
                \begin{split}
                    \lVert f \rVert _1 = \int_{a}^b |f(x)|dx.
                \end{split}
                \end{equation*}           
            Then $(C([a,b]),\lVert \cdot \rVert _1)$ is a normed space.
            \item Let $(V,\lVert \cdot \rVert _V)$ and $(W,\lVert \cdot \rVert _W)$ be normed spaces. Given $T \in \Hom_F(V,W)$, define:
                \begin{equation*}
                \begin{split}
                    \lVert T \rVert _{\text{op}} := \sup_{\lVert v \rVert _V \leq 1} \lVert T(v) \rVert _W.
                \end{split}
                \end{equation*}
            Informally, this measures the maximum factor by which $T$ "lengthens" a vector. If $\lVert T \rVert _\text{op} < \infty$, we say it is a \textit{bounded linear operator}. The space of bounded linear operators is denoted:
                \begin{equation*}
                \begin{split}
                    B_F(V,W) = \{T \in \Hom_F(V,W) \mid \lVert T \rVert _\text{op} < \infty \}.
                \end{split}
                \end{equation*}
            Then $(B_F(V,W),\lVert \cdot \rVert _\text{op})$ is a normed space.
        \end{enumerate}
    \end{example}

    \begin{exercise}\label{exercise:hom-b}
        Show that $\Hom_F(F^n,F^m) = B_F(\ell_2^n,\ell_2^m)$.
    \end{exercise}
        
\section{Inner Product Spaces}
    \begin{definition}
        Let $V$ be a vector space over $F$ and $\varphi:V \times V \rightarrow F$ a map.
            \begin{enumerate}[label = (\arabic*)]
                \item The map $\varphi$ is said to be a \textit{bilinear form} if is is linear in the first and second variable seperately; i.e., for all $v_1,v_2,v \in V$ and $c \in F$ we have:
                    \begin{enumerate}[label = (\roman*)]
                        \item $\varphi(cv_1 +v_2,v) = c\varphi(v_1,v) + \varphi(v_2,v)$
                        \item $\varphi(v,cv_1 + v_2) = \varphi(v,v_1) + c\varphi(v,v_2)$.
                    \end{enumerate}

                \item The map $\varphi$ is said to be a \textit{sesquilinear form} if it is linear in the first variable and conjugate linear in the second variable; i.e., for all $v_1,v_2,v \in V$ and $c \in F$ we have:
                    \begin{enumerate}[label = (\roman*)]
                        \item $\varphi(cv_1 +v_2,v) = c\varphi(v_1,v) + \varphi(v_2,v)$
                        \item $\varphi(v,cv_1 + v_2) = \overline{c}\varphi(v,v_1) + \varphi(v,v_2)$.
                    \end{enumerate}
            \end{enumerate}
        If we wish to keep track of a bilinear form on $V$ we write $(V,\varphi)$.
    \end{definition}

    \begin{definition}
        Let $V$ be a vector space over $F$.
            \begin{enumerate}[label = (\arabic*)]
                \item A bilinear form $\varphi$ on $V$ is said to be \textit{symmetric} if $\varphi(v,w) = \varphi(w,v)$ for all $v,w \in V$.
                \item A sesquilinear form $\varphi$ on $V$ is said to be \textit{Hermitian} if $\varphi(v,w) = \overline{\varphi(w,v)}$ for all $v,w \in V$.
            \end{enumerate}
    \end{definition}

    \begin{definition}
        Let $(V,\varphi)$ be a vector space over $F$ such that if $\varphi$ is symmetric, then $\bfQ \subset F \subset \bfR$ \underline{\textbf{or}} if $\varphi$ is Hermitian, then $\bfQ \subset F \subset \bfC$. We say $\varphi$ is \textit{positive definite} if $\varphi(v,v) > 0$ for all nonzero $v \in V$.
    \end{definition}

    \begin{definition}
        Let $(V,\varphi)$ be a vector space over $\bfR$ with $\varphi$ a positive-definite symmetric bilinear form \underline{\textbf{or}} $\bfC$ with $\varphi$ a positive-definite Hermitian sesquilinear form. Then we say $\varphi$ is an \textit{inner product} on $V$ and write $\varphi$ as $\langle \cdot,\cdot \rangle$. We say $(V,\langle \cdot,\cdot \rangle)$ is an \textit{inner product space}.
    \end{definition}

    \begin{proposition}
        Every inner product space is a normed vector space, with its \textit{canonical norm} defined as:
            \begin{equation*}
            \begin{split}
                \lnorm v \rnorm := \sqrt{\langle v,v \rangle}.
            \end{split}
            \end{equation*}
        In particular, for all $v,w \in V$ and $\alpha \in F$ we have:
            \begin{enumerate}[label = (\arabic*)]
                \item $\lnorm \alpha v \rnorm = |\alpha|\lnorm v \rnorm$;
                \item $|\langle v,w \rangle| \leq \lnorm v \rnorm \lnorm w \rnorm$ (Cauchy-Schwartz Inequality);
                \item $\lnorm v + w \rnorm \leq \lnorm v \rnorm + \lnorm w \rnorm$;
                \item if $\lnorm v \rnorm = 0$ then $v = 0_V$.
            \end{enumerate}
    \end{proposition}
        \begin{proof}
            \iffalse
            Observe that:
                \begin{equation*}
                \begin{split}
                    \lnorm \alpha v \rnorm
                    & = \sqrt{\langle c v, \alpha v \rangle} \\
                    & = \sqrt{\alpha \overline{\alpha}\langle v,v \rangle} \\
                    & = \sqrt{|\alpha|^2 \langle v,v \rangle} \\
                    & = |\alpha| \sqrt{\langle v,v \rangle} \\
                    & = |\alpha| \lnorm v \rnorm.
                \end{split}
                \end{equation*}
            Thus $\lnorm \cdot \rnorm$ satisfies homogeneity. 
                \begin{equation*}
                \begin{split}
                    \lnorm v + w \rnorm ^2 
                    & = \langle v + w, v+w \rangle \\
                    & = \langle v,v \rangle + \langle v,w \rangle + \langle w,v \rangle + \langle w,w \rangle \\
                    & = \lnorm v \rnorm + \langle v,w \rangle + \overline{\langle v,w \rangle} + \lnorm w \rnorm \\
                    & = \lnorm v \rnorm + 2 \text{Re}(\langle v,w \rangle) + \lnorm w \rnorm \\
                    & \leq\lnorm v \rnorm + 2 | \langle v,w \rangle | + \lnorm w \rnorm \\
                    & \leq  \lnorm v \rnorm + 2 \lnorm v \rnorm \lnorm w \rnorm + \lnorm w \rnorm \\
                    & = (\lnorm v \rnorm + \lnorm w \rnorm)^2
                \end{split}
                \end{equation*}
            Taking square roots on both sides establishes the triangle inequality. Lastly, if $\lnorm v \rnorm = \sqrt{\langle v,v \rangle} = 0$, then $\langle v,v \rangle = 0$. Since $V$ is a inner product space, it must be that $v = 0_V$. Thus $(V,\lnorm \cdot \rnorm)$ is a normed space. 
            \fi
        \end{proof}

    \begin{example}
        \phantom{a}
        \begin{enumerate}[label = (\arabic*)]
            \item Note that $\ell_2^n = F^n$. Then $\langle \cdot,\cdot \rangle: \ell_2^n \times \ell_2^n \rightarrow F$ given by
                \begin{equation*}
                \begin{split}
                    \langle x,y \rangle = \sum_{j = 1}^n x_j \overline{y_j}
                \end{split}
                \end{equation*}
            is an inner product.

            \item Recall that $\ell_2 = \{(a_j)_j \in F^\bfN \mid \sum_{j = 1}^\infty |a_j|^2 < \infty\}$. Consider $\langle \cdot,\cdot \rangle:\ell_2 \times \ell_2 \rightarrow F$ given by:
                \begin{equation*}
                \begin{split}
                    \langle (a_j)_j,(b_j)_j \rangle = \sum_{j = 1}^\infty a_j \overline{b_j}.
                \end{split}
                \end{equation*}
            For finite $n$, the Cauchy-Schwartz inequality gives:
                \begin{equation*}
                \begin{split}
                    \left| \sum_{j=1}^n a_j \overline{b_j} \right|
                    & \leq \left( \sum_{j = 1}^n a_j \overline{a_j} \right)^\frac{1}{2} \left( \sum_{j = 1}^n b_j \overline{b_j} \right)^\frac{1}{2} \\
                    & = \left( \sum_{j = 1}^n |a_j|^2 \right)^\frac{1}{2} \left( \sum_{j = 1}^n |b_j|^2 \right)^\frac{1}{2}. \\
                \end{split}
                \end{equation*}
            Taking the limit as $n$ approaches infinity yields:
                \begin{equation*}
                \begin{split}
                    \left| \sum_{j=1}^\infty a_j \overline{b_j} \right|
                    & \leq \left( \sum_{j = 1}^\infty |a_j|^2 \right)^\frac{1}{2} \left( \sum_{j = 1}^\infty |b_j|^2 \right)^\frac{1}{2} \\
                    & < \infty.
                \end{split}
                \end{equation*}
            Thus $\langle (a_j)_j,(b_j)_j \rangle$ is always convergent.
        \end{enumerate}
    \end{example}


    