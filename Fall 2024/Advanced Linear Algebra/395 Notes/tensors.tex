\chapter{Tensor Products, Exterior Algebras, and Determinants}
\vspace{12pt}

\section{Complexification}
    Recall that if $V$ is a $\bfC$-vector space, then $V$ is also an $\bfR$-vector space by restricting the scalars of $\bfC$. A natural question to ask is if $V$ is an $\bfR$-vector space, can we "extend" $V$ to be a $\bfC$-vector space?

    \begin{example}[Complexification of $\bfR$]
        Let $V = \bfR$. We cannot make $\bfR$ into a $\bfC$-vector space. However, we do have $\bfR \hookrightarrow \bfC$ by $x \mapsto x + 0i$, with $\bfC$ as a $\bfC$-vector space. But note that $z \in \bfC$ can we written as $z = x+yi$. There is an isomorphism $\bfR \oplus \bfR \cong \bfC$ as $\bfR$-vector spaces by:
            \begin{equation*}
            \begin{split}
                x+yi \mapsto (x,y)
            \end{split}
            \end{equation*}
        If we take $z = x+yi \in \bfC$ to be a vector, and $a+bi \in \bfC$ to be a scalar, we have:
            \begin{equation*}
            \begin{split}
                (a+bi)(x+yi) = (ax-by)+(ay+bx)i,
            \end{split}
            \end{equation*}
        meaning in $\bfR \oplus \bfR$ we define:
            \begin{equation*}
            \begin{split}
                (a+bi)(x,y) = (ax-by,ay+bx)
            \end{split}
            \end{equation*}
        With scalar multiplication defined as above, then $\bfR \oplus \bfR$ is a $\bfC$-vector space. Furthermore, we have $\bfR \oplus \bfR \cong \bfC$ as \textit{$\bfC$-vector spaces}!
    \end{example}

    \begin{definition}
        Let $V$ be a real vector space. The \textui{complexification} of $V$ is denoted $V_\bfC = V \oplus V$, where complex scalar multiplication is defined by:
            \begin{equation*}
            \begin{split}
                (a+bi)(v_1,v_2) = (av_1 - bv_2, av_2 + bv_1).
            \end{split}
            \end{equation*}
        Upon investigation one can see:
            \begin{equation*}
            \begin{split}
                i(v_1,v_2) = (-v_2,v_1).
            \end{split}
            \end{equation*}
    \end{definition}

    \begin{exercise}
        Prove that $V_\bfC$ is a $\bfC$-vector space.
    \end{exercise}

    \begin{proposition}
        Let $\cB = \{v_i\}_{i \in I}$ be an $\bfR$-basis of $V$. The set $\cB_\bfC = \{(v_j,0_V)\}_{j \in I}$ is a $\bfC$-basis of $V_\bfC$.
    \end{proposition}
        \begin{proof}
            Let $(w_1,w_2) \in V_\bfC$. We can write:
                \begin{equation*}
                \begin{split}
                    w_1 &= \sum_{j \in I}a_j v_j \\
                    w_2 &= \sum_{j \in I}b_j v_j
                \end{split}
                \end{equation*}
            for some $a_j,b_j \in \bfR$. We have:
                \begin{equation*}
                \begin{split}
                     (w_1,w_2)
                     & = \left(\sum_{j \in I}a_jv_j, \sum_{j \in I}b_j v_j\right) \\
                     & = \left(\sum_{j \in I}a_jv_j, 0_V\right) + \left( 0_V, \sum_{j \in I}b_j v_j\right) \\
                     & = \sum_{j \in I}a_j(v_j,0_V) + \sum_{j \in I}b_j(0_V,v_j) \\
                     & = \sum_{j \in I}a_j(v_j,0_V) + \sum_{j \in I}ib_j(v_j,0_V) \\
                     &\in \Span_\bfC \left\{(v_j,0_V)\right\}_{i \in I}.
                \end{split}
                \end{equation*}
            Now suppose we have $(0_V,0_V) = \sum_{j \in I}(a_j + ib_j)(v_j,0_V)$. Then:
                \begin{equation*}
                \begin{split}
                    (0_V,0_V) 
                    &= \sum_{j \in I}(a_j + ib_j)(v_j,0_V) \\
                    & = \sum_{j \in I}a_j(v_j,0_V) + \sum_{j \in I}ib_j(v_j,0_V) \\
                    & = \left(\sum_{j \in I}a_jv_j, 0_V\right) + i \left(\sum_{j \in I}b_jv_j,0_V\right) \\
                    & = \left(\sum_{j \in I}a_jv_j, 0_V\right) + \left(\sum_{j \in I}0_V,b_jv_j\right) \\
                    & = \left(\sum_{j \in I}a_jv_j, \sum_{j \in I}b_jv_j\right),
                \end{split}
                \end{equation*}
            meaning:
                \begin{equation*}
                \begin{split}
                    \sum_{j \in I}a_jv_j &= 0_V \\
                    \sum_{j \in I}b_jv_j &= 0_V.
                \end{split}
                \end{equation*}
            So $a_j = 0$ for all $j$ and $b_j = 0$ for all $j$. Thus $\left\{(v_j,0_V)\right\}_{j \in I}$ are linearly independent.
        \end{proof}

    \begin{proposition}
        Let $V,W$ be $\bfR$-vector spaces, and let $T \in \Hom_\bfR(V,W)$. There is a unique $T_\bfC \in \Hom_\bfC(V_\bfC,W_\bfC)$ that makes the following diagram commute:
            \begin{center}
                \begin{tikzcd}
                    V \arrow[d, "\iota_V"', hook] \arrow[r, "T"] & W \arrow[d, "\iota_W", hook] \\
                    V_\bfC \arrow[r, "T_\bfC"']                  & W_\bfC                      
                \end{tikzcd}
            \end{center}
    \end{proposition}
        \begin{proof}
            Define 
                \begin{equation*}
                \begin{split}
                    T_\bfC(v_1,v_2) = (T(v_1),T(v_2)).
                \end{split}
                \end{equation*}
            Let $v \in V$. We have $\iota_V(v) = (v,0_V)$, meaning:
                \begin{equation*}
                \begin{split}
                    T_\bfC(\iota_V(v)) 
                    &= T_\bfC((v,0_V)) \\
                    & = (T(v),T(0_V)) \\
                    & = (T(v),0_W),
                \end{split}
                \end{equation*}
            and:
                \begin{equation*}
                \begin{split}
                    \iota_W(T(v)) = (T(v),0_W).
                \end{split}
                \end{equation*}
            Hence the diagram commutes. We claim that $T_\bfC$ is $\bfC$-linear. Let $x+iy \in \bfC$ and $(v_1,v_2),(v_1',v_2
            ) \in V_\bfC$. Then:
                \begin{equation*}
                \begin{aligned}
                T_{\mathbf{C}}\left(\left(v_1, v_2\right)+(x+\mathrm{iy})\left(v_1^{\prime}, v_2^{\prime}\right)\right) & =T_{\mathbf{C}}\left(\left(v_1, v_2\right)+\left(x v_1^{\prime}-y v_2^{\prime}, x v_2^{\prime}+y v_1^{\prime}\right)\right) \\
                & =T_{\mathbf{C}}\left(\left(v_1+x v_1^{\prime}-y v_2^{\prime}, v_2+x v_2^{\prime}+y v_1^{\prime}\right)\right) \\
                & =\left(T\left(v_1+x v_1^{\prime}-y v_2^{\prime}\right), T\left(v_2+x v_2^{\prime}+y v_1^{\prime}\right)\right) \\
                & =\left(T\left(v_1\right), T\left(v_2\right)\right)+x\left(\mathrm{~T}\left(v_1^{\prime}\right), T\left(v_2^{\prime}\right)\right)+y\left(-T\left(v_2^{\prime}\right), T\left(v_1^{\prime}\right)\right) \\
                & =\left(T\left(v_1\right), T\left(v_2\right)\right)+(x+i y)\left(T\left(v_1^{\prime}\right), T\left(v_2^{\prime}\right)\right) \\
                & =T_{\mathbf{C}}\left(v_1, v_2\right)+(x+\mathrm{iy}) T_{\mathbf{C}}\left(v_1^{\prime}, v_2^{\prime}\right) .
                \end{aligned}
                \end{equation*}
            Hence $T_\bfC$ is linear. Now suppose there is an $S \in \Hom_\bfC(V_\bfC,W_\bfC)$ making the following diagram commute:
                \begin{center}
                    \begin{tikzcd}
                        V \arrow[d, "\iota_V"', hook] \arrow[r, "T"] & W \arrow[d, "\iota_W", hook] \\
                        V_\bfC \arrow[r, "S"']                  & W_\bfC                      
                    \end{tikzcd}
                \end{center}
            Let $v_1,v_2 \in V_\bfC$. Then:
                \begin{equation*}
                \begin{split}
                    S((v_1,v_2))
                    & = S((v_1,0_V) + (0_V,v_2)) \\
                    & = S((v_1,0_V) + i(v_2,0_V)) \\
                    & = S((v_1,0_V)) + iS((v_2,0_V)) \\
                    & = S(\iota_V(v_1)) + iS(\iota_V(v_2)) \\
                    & = \iota_W(T(v_1)) + i \iota_W(T(v_2)) \\
                    & = (T(v_1),0_W) + i(T(v_2),0_W) \\
                    & = (T(v_1,0_W)) + (0_W,T(v_2)) \\
                    & = (T(v_1),T(v_2)) \\
                    & = T_\bfC((v_1,v_2)).
                \end{split}
                \end{equation*}
            Thus $T_\bfC$ is unique.
        \end{proof}

\section{Free Vector Spaces}
    We showed in Section~\ref{section:vector-bases} that every vector space has a basis. In this section we show that given a set $X$, we can build a vector space that "has" $X$ as a basis. We will give a few basic definitions before investigating the properties of these spaces.

    \begin{definition}
        Let $f:\Omega \rightarrow F$ be a map whose domain is an arbitrary set $\Omega$. The \textui{support} if $f$, denoted $\supp(f)$ is the set of points in $\Omega$ where $f$ is nonzero:
            \begin{equation*}
            \begin{split}
                \supp(f) = \{x \in \Omega \mid f(x) \neq 0\}.
            \end{split}
            \end{equation*}
    \end{definition}

    \begin{definition}
        Let $F$ be a field. The set of all functions from $\Omega$ to $F$ is denoted:
            \begin{equation*}
            \begin{split}
                \cF(\Omega,F) = \{f \mid f:\Omega \rightarrow F\}.
            \end{split}
            \end{equation*}
    \end{definition}

    \begin{exercise}
        Show that $\cF(\Omega,F)$ is an $F$-vector space.
    \end{exercise}

    \begin{example}
        Fix $t \in \Gamma$. Recall that $\delta_t:\Gamma \rightarrow F$ is defined by:
            \begin{equation*}
            \begin{split}
                \delta_t (s) = \begin{cases} 1, & s = t \\ 0, & s \neq t \end{cases}.
            \end{split}
            \end{equation*}
        We have that $\delta_t \in \cF(\Gamma,F)$, and furthermore $\supp(\delta_t) = \{t \}$. If $f \in \cF(\Gamma,F)$ has finite support, then $\supp(f) = \{t_1,...,t_n\}$ for some $t_i \in F$. If:
            \begin{equation*}
            \begin{split}
                f(t_1) &= \alpha_1 \neq 0 \\
                f(t_2) &= \alpha_2 \neq 0 \\
                &\vdots \\
                f(t_n) &= \alpha_n \neq 0, \\
            \end{split}
            \end{equation*}
        then we can write $f = \sum_{j = 1}^n \alpha_j \delta_{t_j}$.
    \end{example}

    \begin{theorem}[Existence of Free Vector Spaces]\label{thm:free-vectorspace}
        Let $F$ be a field and $\Gamma$ a set. There is an $F$-vector space $\bbF(\Gamma)$ that has a basis isomorphic to $\Gamma$ as sets. Moreover, $\bbF(\Gamma)$ has the following universal property: if $W$ is any $F$-vector space and $t:\Gamma \rightarrow W$ is a map of sets, there is a unique $T \in \Hom_F(\bbF(\Gamma),W)$ such that $T(x) = t(x)$ for every $x \in \Gamma$; i.e., the following diagram commutes:
            \begin{center}
            \begin{tikzcd}
                \Gamma \arrow[r, "\iota", hook] \arrow[rd, "t"'] & \bbF(\Gamma) \arrow[d, "T"] \\
                                                            & W                  
            \end{tikzcd}
            \end{center}
    \end{theorem}
        \begin{proof}
            If $\Gamma$ is the empty set, take $\bbF(\Gamma) = \{0\}$. Let $\Gamma \neq \emptyset$. Define:
                \begin{equation*}
                \begin{split}
                    \bbF(\Gamma) = \{f:\Gamma \rightarrow F \mid \supp(f) < \infty\}.
                \end{split}
                \end{equation*}
            Since $\bbF(\Gamma) \subseteq \cF(\Gamma,F)$, this space inherits a natural vector space structure. In particular, if $f,g$ are finitely supported functions and $c \in F$, then $(f+g)(x) = f(x) + f(x)$ and $(cf)(x) = c f(x)$ will be finitely supported. Moreover, the zero element of this set if $f(x) = 0_{\bbF(\Gamma)}$. The rest of the vector space axioms are left as an exercise.

            We obtain an inclusion $\iota: \Gamma \hookrightarrow \bbF(\Gamma)$ by $x \mapsto \delta_x$. Let $\cX = \{\delta_x \mid x \in \Gamma\}$. This a subset of $\bbF(\Gamma)$ and furthermore we have a bijection $\Gamma \hooktwoheadrightarrow \cX$.

            Let $f \in \bbF(\Gamma)$. We can write $f = \sum_{x \in \Gamma}f(x)\delta_x \in \Span_F(\cX)$. Hence $\Span_F(\cX) = \bbF(\Gamma)$. Note that:
                \begin{equation*}
                \begin{split}
                    f(y)
                    & = f(y)\delta_y(y) \\
                    & = f(y)\delta(y)(y) + \sum_{x \neq y}f(x)\delta_x(y) \\
                    & = \sum_{x \in \Gamma}f(y)\delta_x(y).
                \end{split}
                \end{equation*}
            Note that $f(y)$ is just a scalar in $F$, hence an arbitrary element of $\bbF(\Gamma)$ looks like $\sum_{i = 1}^n a_i \delta_{x_i}$. Suppose then that $\sum_{i = 1}^n a_i \delta_{x_i} = 0_{\bbF(\Gamma)}$. We have that $\sum_{i = 1}^n a_i \delta_{x_i}(y) = 0_F$ for all $y \in \Gamma$. Thus:
                \begin{equation*}
                \begin{split}
                    0_F 
                    & = \sum_{i = 1}^n a_i \delta_{x_i}(x_j) \\
                    & = a_j.
                \end{split}
                \end{equation*}
            This establishes $\cX$ as a basis for $\bbF(\Gamma)$.

            Now suppose we have $t: \Gamma \rightarrow W$. Define $T: \bbF(\Gamma) \rightarrow W$ by:
                \begin{equation*}
                \begin{split}
                    T \left(\sum_{i = 1}^n a_i \delta_{x_i}\right) = \sum_{i =1}^n a_i t(\iota^{-1}(\delta_{x_i})).
                \end{split}
                \end{equation*}
            Because $\cX$ is a basis, this gives a well-defined linear map. It is unique because any linear map that agrees with $t$ on $\cX$ must agree with $T$ on $\bbF(\Gamma)$, establishing the proof.
        \end{proof}

        \begin{example}
            If $\Gamma = \bfR$, we can form $\bbF_\bfR(\bfR)$. An example of  an element of $\bbF_\bfR(\bfR)$ is $2 \cdot \pi + 3 \cdot 2$, where $\pi,2$ are basis elements and $2,3$ are scalars. Note that, from this construction, we cannot simplify this expression.
        \end{example}
    
        \begin{exercise}
            Show that if $\Gamma = \{x_1,...,x_n\}$, then $\bbF(\Gamma) \cong F^n$.
        \end{exercise}

\section{Extension of Scalars}
    Let $V$ be an $F$-vector space and $K/F$ an extension of fields. We can naturally consider $K$ as an $F$-vector space. As we did with complexification, we want to define a way to "multiply" vectors in $V$ by scalars in $K$. The way we define "multiplication" should be obvious: Let $a, a_1,a_2 \in K$, $c\in F$, and $v,v_1,v_2 \in V$. We want multiplication to satisfy:
        \begin{enumerate}[label = (\arabic*)]
            \item $(a_1 + a_2) \star v$;
            \item $a \star (v_1 + v_2) = a \star v_1 + a \star v_2$;
            \item $(ac) \star v = a \star (cv)$.
        \end{enumerate}
    We will construct a vector space that satisfies exactly this by constructing the \textit{tensor product} of $V$ with $K$.

    \begin{definition}
        Let $V$ be an $F$-vector space and $K/F$ be an extension of fields. Let $K \times V$ be the Cartesian product of $K$ and $V$ and define:
            \begin{equation*}
            \begin{split}
                \cA_1 &= \{(a_1 + a_2,v)-(a_1,v)-(a_2,v) \mid a_1,a_2 \in K, v\in V\}, \\
                \cA_2 &= \{(a,v_1 + v_2) - (a,v_1) - (a,v_2) \mid a \in K, v_1,v_2 \in V\}, \\
                \cA_3 &= \{(ca,v) - (a,cv) \mid c \in F, a \in K, v\in V\}, \\
                \cA_4 &= \{a_1(a_2,v) - (a_1 a_2,v) \mid a_1,a_2 \in K,v \in V\}.
            \end{split}
            \end{equation*}
        Define $\Rel_K(K \times V) = \Span_F(\cA_1,\cA_2,\cA_3,\cA_4)$. The \textui{tensor product} of $K$ and $V$ over $F$ is:
            \begin{equation*}
            \begin{split}
                K \otimes_F V = \bbF(K \times V)/\Rel_K(K \times V).
            \end{split}
            \end{equation*}
        For any arbitrary element $\sum_{\text{\tiny finite}}c_i \delta_{a_i,v_i} \in \bbF(K \times V)$, we denote the equivalence class \newline $\sum_{\text{\tiny finite}}c_i \delta_{a_i,v_i} + \Rel_K(K \times V)$ as:
            \begin{equation*}
            \begin{split}
                \sum_{\text{finite}}c_i(a_i \otimes v_i)
                & = \sum_{\text{finite}}c_i a_i(1 \otimes v_i) \\
                & = \sum_{\text{finite}}b_i \otimes v_i
            \end{split}
            \end{equation*}
        for some $b_i \in K$. An element of the form $a \otimes v$ is referred to as a \textui{pure tensor}. Both arbitrary elements of $K \otimes_F V$ and pure tensors admit the following properties:
            \begin{enumerate}[label = (\arabic*)]
                \item $(a_1 + a_2) \otimes v = a_1 \otimes v + a_2 \otimes v$ for all $a_1,a_2 \in K$, $v \in V$;
                \item $a \otimes (v_1 + v_2) = a \otimes v_1 + a \otimes v_2$ for all $a \in K$, $v_1,v_2 \in V$;
                \item $ca \otimes v = a \otimes cv$ for all $c \in F$, $a \in K$, and $v \in V$;
                \item $a_1(a_2 \otimes v) = (a_1 a_2)\otimes v$ for all $a_1,a_2 \in K$, $v \in V$.
            \end{enumerate}
    \end{definition}

    \begin{note}
        \phantom{a}
        \begin{enumerate}[label = (\arabic*)]
            \item An \textbf{arbitrary element of $K \otimes_F V$ is a finite sum.} It is a common mistake when working with tensor products to check things for pure tensors and not with arbitrary elements.
            \item Since $K \otimes_F V$ is a quotient space, there must be care in checking things are well-defined when working with tensor products. 
        \end{enumerate}
    \end{note}

    \begin{exercise}
        Show that $K \otimes_F V$ is a $K$-vector space. (Hint: $0 \otimes 0_V$ is the additive identity in $K \otimes_F V$).
    \end{exercise}

    \begin{proposition}\label{prop:basis-of-tensor}
        Let $K/F$ be a field extension and $V$ an $F$-vector space with basis $\cB = \{v_i\}_{i \in I}$. We have $\Span_K \left\{1 \otimes v_i\right\}_{i \in I} = K \otimes_F V$.
    \end{proposition}
        \begin{proof}
            Let $a \otimes v \in K\otimes_F V$. Write $v = \sum_{i=1}^n c_i v_i$ for some $c_i \in F$. We have:
                \begin{equation*}
                \begin{split}
                    a \otimes v 
                    & = a \otimes \left(\sum_{i=1}^n c_i v_i\right) \\
                    & = \sum_{i = 1}^n a \otimes c_i v_i \\
                    & = \sum_{i = 1}^n ac_i \otimes v_i \\
                    & = \sum_{i = 1}^n ac_i(1 \otimes v_i).
                \end{split}
                \end{equation*}
            From this, it follows that every pure tensor $a \otimes v$ is also in the span of $\{1 \otimes v_i\}_{i \in I}$. This gives that all finite sums of the form $\sum_{j \in I}a_j \otimes \tilde{v}_j$ are also in the span of $\{1 \otimes v_i\}_{i \in I}$. Hence $\Span_F \left\{1 \otimes v_i\right\}_{i \in I} = K \otimes_F V$.
        \end{proof}

    \begin{theorem}
        Let $K/F$ be an extension of fields, $V$ an $F$-vectorspace, and $\iota_V:V \rightarrow K \otimes_F V$ defined by $\iota_V (v) = 1 \otimes v$. Let $W$ be any $K$-vector space and $S \in \Hom_F(V,W)$. There is a unique $T \in \Hom_K(K \otimes_F V,W)$ so that $S = T \circ \iota_V$; i.e., the following diagram commutes:
            \begin{center}
                \begin{tikzcd}
                    V \arrow[r, "\iota_V"] \arrow[rd, "S"'] & K \otimes_F V \arrow[d, "T"] \\
                                                            & W                           
                \end{tikzcd}
            \end{center}
        Conversely, if $T \in \Hom_K(K \otimes_F V,W)$, then $T \circ \iota_V \in \Hom_F(V,W)$.
    \end{theorem}
        \begin{proof}
            Let $S \in \Hom_F(V,W)$. Recall we constructed $K \otimes_F V$ as a quotient of $\bbF(K \times V)$. Define:
                \begin{equation*}
                \begin{split}
                    t: K \times V \rightarrow W \mtext{by} (a,v) \mapsto aS(v)
                \end{split}
                \end{equation*}
            as a map of sets. Theorem~\ref{thm:free-vectorspace} tells us that $t$ extends to a map $T \in \Hom_K(\bbF(K \times V), W)$ such that $T((a,v)) = t((a,v))$. Since $T$ is linear:
                \begin{equation*}
                \begin{split}
                    T \left(\sum_{i \in I} c_i(a_i,v_i)\right)
                    & = \sum_{i \in I}T(c_i(a_i,v_i)) \\
                    & = \sum_{i \in I}c_i T((a_i,v_i)) \\
                    & = \sum_{i \in I}c_i t((a_i,v_i)) \\
                    & = \sum_{i \in I}c_i a_i S(v_i). \\
                \end{split}
                \end{equation*}
            We must check that $T$ is the zero map when restricted to $\Rel_K(K \times V)$. We have:
                \begin{equation*}
                \begin{split}
                    T((a+b,v)-(a,v)-(b,v))
                    & = T((a+b,v)) - T((a,v)) - T((b,v)) \\
                    & = (a+b)S(v) - aS(v) - bS(v) \\
                    & = 0_W.
                \end{split}
                \end{equation*}
            The rest of the relations are left as an exercise. Thus we have $T \in \Hom_K(K \otimes_F V , W)$ defined by $T \left(\sum_{i \in I}c_i(a_i \otimes v_i)\right) = \sum_{i \in I}c_i a_i S(v_i)$. To see that the diagram commutes, observe that:
                \begin{equation*}
                \begin{split}
                    T(\iota_V(v)) = T(1 \otimes v) = 1 \cdot S(v) = S(v).
                \end{split}
                \end{equation*}
            From Proposition~\ref{prop:basis-of-tensor}, we saw that $K \otimes_F V$ is spanned by elements of the form $1 \otimes v$. Hence any linear map on $K \otimes_F V$ is determined by the image of these elements. Since $T(1 \otimes v) = S(v)$, we get $T$ is uniquely determined by $S$.

            The converse statement that for any $T \in \Hom_K(K \otimes_F V)$ one has $T \circ \iota_V \in \Hom_F(V,W)$ is left as an exercise.
        \end{proof}

    \begin{exercise}
        Complete the proof that $T$ vanishes on all the relations.
    \end{exercise}

    \begin{exercise}
        Given $T \in \Hom_K(K \otimes_F V,W)$, show $T \circ \iota_V \in \Hom_F(V,W)$.
    \end{exercise}

    \begin{proposition}
        Let $K/F$ be an extension of fields. Then $K \otimes_F F \cong K$ as $K$-vector spaces. 
    \end{proposition}
        \begin{proof}
            There is a natural inclusion map $i: F \rightarrow K$. Let $\iota:F \rightarrow K \otimes_F F$. By the universal property we obtain a unique $K$-linear map $T: K \otimes_F F \rightarrow K$ so that the following diagram commutes:
                \begin{center}
                    \begin{tikzcd}
                        F \arrow[rd, "i"', hook] \arrow[r, "\iota"] & K \otimes_F F \arrow[d, "T"] \\ & K                           
                    \end{tikzcd}
                \end{center}
            We see that $T(1 \otimes x) = i(x)= x$. Since $T$ is $K$-linear this completely determines $T$ because, for $\sum_{i \in I}a_i \otimes x_i \in K \otimes_F F$, we have:
                \begin{equation*}
                \begin{split}
                    T \left(\sum_{i \in I}a_i \otimes x_i\right)
                    & = \sum_{i \in I}T(a_i \otimes x_i) \\
                    & = \sum_{i \in I}T(a_i(1 \otimes x_i)) \\
                    & = \sum_{i \in I} a_i T(1 \otimes x_i) \\
                    & = \sum_{i \in I}a_i x_i.
                \end{split}
                \end{equation*}
            If we show $T$ has an inverse map, then we obtain an isomorphism. Let $S:K \rightarrow K \otimes_F F$ defined by $y \mapsto y \otimes 1$. Let $a \in K$, and $y_1, y_2 \in K$. Then:
                \begin{equation*}
                \begin{split}
                    S(y_1 + a y_2)
                    & = ... 
                \end{split}
                \end{equation*}
            Hence $S \in \Hom_K(K,K \otimes_F F)$. Since $S,T$ are linear, it is enough to check that they are inverses with pure tensors. Observe that:
                \begin{equation*}
                \begin{split}
                    T(S(y)) &= T(y \otimes 1) = y T(1 \otimes 1) = y \\
                    S(T(a \otimes x)) &= S(a T(1 \otimes x)) = S(ax) = ax \otimes 1 = a \otimes x.
                \end{split}
                \end{equation*}
            Thus $T^{-1} = S$, and so $K \otimes_F F  \cong K$ as $K$-vector spaces.
        \end{proof}

    \begin{example}
        From the previous section, we can now see that $\bfR_\bfC = \bfC \otimes_\bfR \bfR \cong \bfC$.
    \end{example}

    \begin{example}
        It is not always obvious that an element of $K \otimes_F F$ is nonzero. Take for example $\bfZ/2\bfZ \otimes_\bfZ \bfZ$. We have that $1 \otimes 2 = 2 \otimes 1 = 0_{\bfZ/2\bfZ} \otimes 1 = 0_{\bfZ/2\bfZ \otimes_\bfZ \bfZ}$.
    \end{example}

    \begin{exercise}
        Show that $V_\bfC \cong \bfC \otimes_\bfR V$.
    \end{exercise}

    \begin{proposition}
        Let $K/F$ be an extension of fields and $V$ an $F$-vector space with $\dim_F V = n$. Then $K \otimes_F V \cong K^n$ as $K$-vector spaces.
    \end{proposition}
        \begin{proof}
            We want a $K$-linear map $K \otimes_F V \rightarrow K^n$. Take $\cB = \{v_1,...,v_n\}$ to be a basis for $V$ and $\cE_n = \{e_1,...,e_n\}$ the standard basis for $K^n$. Define a map $t:V \rightarrow K^n$ by $t(v_i) = e_i$. Since this map is defined on a basis, it extends to an $F$-linear map. So $t \in \Hom_F(V,K^n)$. The universal property gives $T \in \Hom_K(K \otimes_F V, K^n)$ so that $T(1 \otimes v_i) = e_i$. We will show that $T$ has an inverse. Define $S \in \Hom_K(K^n,K \otimes_F V)$ by $S(e_i) = 1 \otimes v_i$. These are clearly inverse maps, so $K \otimes_F V \cong K^n$. Moreover, since $S$ is invertible and the $e_i$ are a basis, $\{S(e_i)\}_{i =1}^n$ gives a basis of $K \otimes_F V$; i.e., $\{1 \otimes v_i\}_{i = 1}^n$ is a basis.
        \end{proof}

    \begin{proposition}
        Let $K/F$ be an extension of fields and $V$ an $F$-vector space. Let $\cB = \{v_i\}_{i \in I}$ be an $F$-basis of $V$. We have $\cB_K = \{1 \otimes v_i\}_{i \in I}$ is a basis of $K \otimes_F V$.
    \end{proposition}
        \begin{proof}
            We saw in Proposition~\ref{prop:basis-of-tensor} that $\cB_K$ spans $K \otimes_F V$. Suppose there exists a linear dependence $\sum_{i \in I}c_i(1 \otimes v_i) = 0_{K \otimes_F V}$. Given $(b,v) \in K \times V$, write $(b,\sum_{i \in I}a_i v_i)$ for some $a_i \in F$. Fix $i_0 \in I$ and define:
                \begin{equation*}
                \begin{split}
                    t_{i_0}: V \rightarrow K
                \end{split}
                \end{equation*}
            by $t_{i_0}(v) = t_{i_0}(\sum_{i \in I}a_i v_i) = a_{i_0}$. One can check that $t_{i_0} \in \Hom_F(V,K)$. The universal property extends this to $T_{i_0} \in \Hom_K(K \otimes_F V, K)$ so that $T_{i_0}(1 \otimes v) = t_{i_0}(v) = a_{i_0}$. Recall that $\sum_{i \in I}c_i(1 \otimes v_i) = 0_{K \otimes_F V}$. Observe that:
                \begin{equation*}
                \begin{split}
                    0_K 
                    &= T_{i_0}(0_{K \otimes_F V}) \\
                    & = T_{i_0}\left(\sum_{i \in I}c_i (1 \otimes v_i)\right) \\
                    & = \sum_{i \in I}c_i T_{i_0}(1 \otimes v_i) \\
                    & = \sum_{i \in I}c_i t_{i_0}(v_i) \\
                    & = c_{i_0}.
                \end{split}
                \end{equation*}
            Since $i_0 \in I$ was arbitrary, we have that $c_i = 0$ for all $i \in I$; i.e., $\cB_K$ is linearly independent. Thus $\cB_K$ is a basis of $K \otimes_F V$.
        \end{proof}

    \begin{theorem}
        Let $K/F$ be an extension of fields and $V,W$ both $F$-vector spaces. Given $T \in \Hom_F(V,W)$, there is a unique map $T_K \in \Hom_K(K \otimes_F V, K \otimes_F W)$ so that the following diagram commutes:
            \begin{center}
                \begin{tikzcd}
                    V \arrow[r, "T"] \arrow[d, "\iota_V"', hook] & W \arrow[d, "\iota_W", hook] \\
                    K\otimes_F V \arrow[r, "T_K"']               & K\otimes_F W                
                    \end{tikzcd}
            \end{center}
    \end{theorem}
        \begin{proof}
            Define $t:V \rightarrow K \otimes_F W$ by $t(v) = 1 \otimes T(v)$. It can be shown that $t \in \Hom_F(V, K\otimes_F W)$. The universal property extends this to a unique map $T_K \in \Hom_K(K \otimes_F V, K\otimes_F W)$ so that $t = T_K \circ \iota_V$. Let $v \in V$. We have that $\iota_W(T(v)) = 1 \otimes T(v) = t(v) = (T_K \circ \iota_V)(v)$, meaning the diagram commutes.
        \end{proof}
    
    \begin{exercise}
        Let $V$ be an $\bfR$-vector space. We have $\bfC \otimes_\bfR V \cong V_\bfC$.
    \end{exercise}

\section{Tensor Products of Vector Spaces}
    \begin{definition}
        Let $U,V,W$ be $F$-vector spaces. If $t:V \times W \rightarrow U$ satisfies:
            \begin{enumerate}[label = (\arabic*)]
                \item ${t}\left(v_1+v_2, w\right)={t}\left(v_1, w\right)+{t}\left(v_2, w\right)$;
                \item ${t}\left(v, w_1+w_2\right)={t}\left(v, w_1\right)+{t}\left(v, w_2\right)$;
                \item ${ct}(v, w)={t}({c} v, w)={t}(v, {c} w)$;
            \end{enumerate}
        we call $t$ a \textui{bilinear map}. The collection of bilinear maps is denoted $\Hom_F(V,W;U)$. If $t \in \Hom_F(V,V;F)$, then we say $t$ is a \textui{bilinear form}.
    \end{definition}

    \begin{example}
        \phantom{a}
        \begin{enumerate}
            \item The standard dot product $\bfR^n \times \bfR^n \rightarrow \bfR$ is a bilinear form.
            \item The standard cross-product in $\bfR^3 \times \bfR^3 \rightarrow \bfR^3$ is a bilinear map.
        \end{enumerate}
    \end{example}